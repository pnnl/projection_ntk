{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9e5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import rearrange\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458a44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PATH = sys.path\n",
    "newPATH = ['/rcfs/projects/task0_pmml/TRAKfork/trak',] + PATH\n",
    "sys.path = newPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653d1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using 1 model because we have only 1 model?\n",
    "ckpts = [torch.load('/rcfs/projects/task0_pmml/MODELS/poisoned_CNN.pt'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23217ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trak import TRAKer\n",
    "from trak.modelout_functions import pNTKModelOutput "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a0fe94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv2d = torch.nn.Conv2d(3, 32, (3,3), padding=(1,1),)\n",
    "        self.batch_normalization = torch.nn.BatchNorm2d(32,momentum=0.01,eps=1e-3)\n",
    "        self.conv2d_1 = torch.nn.Conv2d(32, 32, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_1 = torch.nn.BatchNorm2d(32,momentum=0.01,eps=1e-3)\n",
    "        self.max_pooling2d = torch.nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_2 = torch.nn.BatchNorm2d(64,momentum=0.01,eps=1e-3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_3 = torch.nn.BatchNorm2d(64,momentum=0.01,eps=1e-3)\n",
    "        self.max_pooling2d_1 = torch.nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 128, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_4 = torch.nn.BatchNorm2d(128,momentum=0.01,eps=1e-3)\n",
    "        self.conv2d_5 = torch.nn.Conv2d(128, 128, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_5 = torch.nn.BatchNorm2d(128,momentum=0.01,eps=1e-3)\n",
    "        self.max_pooling2d_2 = torch.nn.MaxPool2d((2,2))\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.max_pooling1d = torch.nn.MaxPool1d((4))\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.dense = torch.nn.Linear(512,512,)\n",
    "        self.batch_normalization_6 = torch.nn.BatchNorm1d(512,momentum=0.01,eps=1e-3)\n",
    "        \n",
    "        self.dense_1 = torch.nn.Linear(512,512,)\n",
    "        self.batch_normalization_7 = torch.nn.BatchNorm1d(512,momentum=0.01,eps=1e-3)\n",
    "        \n",
    "        self.dense_2 = torch.nn.Linear(512,10,)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv2d(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization(x)\n",
    "        x = self.conv2d_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_1(x)\n",
    "        x = self.max_pooling2d(x)\n",
    "        \n",
    "        x = self.conv2d_2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_3(x)\n",
    "        x = self.max_pooling2d_1(x)\n",
    "        \n",
    "        x = self.conv2d_4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_4(x)\n",
    "        x = self.conv2d_5(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_5(x)\n",
    "        x = self.max_pooling2d_2(x)\n",
    "        \n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.max_pooling1d(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.dense(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_6(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_7(x)\n",
    "        x = self.dense_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6248490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to('cuda').eval()\n",
    "#torch.manual_seed(1234)\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(),1e-2,momentum=0.9,nesterov=True)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853ebe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f3b36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:TRAK:TRAK is still in an early 0.x.x version.\n",
      "                             Report any issues at https://github.com/MadryLab/trak/issues\n",
      "INFO:STORE:No existing model IDs in /rcfs/projects/task0_pmml/proj_trNTK/traceback_pNTK_full.\n",
      "INFO:STORE:No existing TRAK scores in /rcfs/projects/task0_pmml/proj_trNTK/traceback_pNTK_full.\n"
     ]
    }
   ],
   "source": [
    "traker = TRAKer(model=model,\n",
    "                task='pNTK',\n",
    "                save_dir = '/rcfs/projects/task0_pmml/proj_trNTK/traceback_pNTK_full/',\n",
    "                train_set_size=70_000,\n",
    "                num_classes=None,\n",
    "                proj_dim=0,\n",
    "                use_half_precision=False,\n",
    "                proj_max_batch_size=16,\n",
    "                projector=trak.projectors.NoOpProjector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919e9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/rcfs/projects/task0_pmml/traceback/forensics/results/cifar_cifar2_res.p','rb') as f:\n",
    "    RES = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d80641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_201960/846220996.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y_all = torch.tensor(torch.argmax(test_y_all,axis=1),dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "RES.keys()\n",
    "\n",
    "train_x = rearrange(torch.tensor(RES['injected_X'],dtype=torch.float32),'b h w c -> b c h w')\n",
    "train_y = torch.argmax(torch.tensor(RES['injected_Y'],dtype=torch.long),axis=1)\n",
    "\n",
    "test_x = rearrange(torch.tensor(RES['injected_X_test'],dtype=torch.float32),'b h w c -> b c h w')\n",
    "test_y = torch.tensor(RES['injected_Y_test'],dtype=torch.float32)\n",
    "\n",
    "test_x_og = rearrange(torch.tensor(RES['X_test'],dtype=torch.float32),'b h w c -> b c h w')\n",
    "test_y_og = torch.tensor(RES['Y_test'],dtype=torch.float32)\n",
    "\n",
    "\n",
    "test_x_all = rearrange(torch.cat([torch.tensor(RES['injected_X_test'],dtype=torch.float32),torch.tensor(RES['X_test'],dtype=torch.float32)]),'b h w c -> b c h w')\n",
    "test_y_all = torch.cat([torch.tensor(RES['injected_Y_test'],dtype=torch.long),torch.tensor(RES['Y_test'],dtype=torch.long)])\n",
    "\n",
    "test_y_all = torch.tensor(torch.argmax(test_y_all,axis=1),dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x,train_y),batch_size=100,shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(test_x,test_y),batch_size=1,shuffle=False)\n",
    "test_loader_og = DataLoader(TensorDataset(test_x_og,test_y_og),batch_size=1,shuffle=False)\n",
    "\n",
    "\n",
    "test_loader_all = DataLoader(TensorDataset(test_x_all,test_y_all),batch_size=100,shuffle=False)\n",
    "\n",
    "\n",
    "#train, poisoned, original\n",
    "x_all = torch.cat([train_x,test_x,test_x_og])\n",
    "y_all = torch.cat([train_y,torch.argmax(test_y,axis=1),torch.argmax(test_y_og,axis=1)])\n",
    "loader_all = DataLoader(TensorDataset(x_all,y_all),batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32b769",
   "metadata": {},
   "source": [
    "# CUDA projector, took 1min to calculate proj-pNTK\n",
    "\n",
    "(nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5cb41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/700 [00:00<?, ?it/s]/tmp/ipykernel_201960/2375125120.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[1] = torch.tensor(batch[1],dtype=torch.long)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 700/700 [07:04<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for model_id, ckpt in enumerate(ckpts):\n",
    "    # TRAKer loads the provided checkpoint and also associates\n",
    "    # the provided (unique) model_id with the checkpoint.\n",
    "    traker.load_checkpoint(ckpt, model_id=model_id)\n",
    "\n",
    "    for batch in tqdm(loader_all):\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        batch[1] = torch.tensor(batch[1],dtype=torch.long)\n",
    "        # TRAKer computes features corresponding to the batch of examples,\n",
    "        # using the checkpoint loaded above.\n",
    "        traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "# Tells TRAKer that we've given it all the information, at which point\n",
    "# TRAKer does some post-processing to get ready for the next step\n",
    "# (scoring target examples).\n",
    "#traker.finalize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
