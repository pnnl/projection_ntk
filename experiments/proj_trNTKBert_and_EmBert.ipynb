{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041ebdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import rearrange\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57aaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PATH = sys.path\n",
    "newPATH = ['/rcfs/projects/task0_pmml/TRAKfork/trak',] + PATH\n",
    "sys.path = newPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f29e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using 1 model because we have only 1 model?\n",
    "ckpts = [torch.load('/rcfs/projects/task0_pmml/BERT/model_frozen.pt'),\n",
    "        torch.load('/rcfs/projects/task0_pmml/BERT/one_gpu_development/MANY_BERT_MODELS/BERT-base_SEED1.pt'),\n",
    "        torch.load('/rcfs/projects/task0_pmml/BERT/one_gpu_development/MANY_BERT_MODELS/BERT-base_SEED2.pt'),\n",
    "        torch.load('/rcfs/projects/task0_pmml/BERT/one_gpu_development/MANY_BERT_MODELS/BERT-base_SEED3.pt')]\n",
    "\n",
    "for ckpt in ckpts:\n",
    "    ckpt.pop('bert.embeddings.position_ids')\n",
    "    \n",
    "#I think in earlier versions this weight exists; in the current version it is unused. It\n",
    "#seems to just be arange..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67520aa2",
   "metadata": {},
   "source": [
    "# Define models and dataset setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec33f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 09:06:44.341837: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 09:06:56.927092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 2,   \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f63f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# because the dataset is int tsv format we have to use delimeter.\n",
    "df = pd.read_csv(\"../cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_sources', 'label', 'label_note', 'sentence'])\n",
    "\n",
    "# creating a copy so we don't messed up our original dataset.\n",
    "data=df.copy()\n",
    "\n",
    "data.drop(['sentence_sources','label_note'],axis=1,inplace=True)\n",
    "sentences=data.sentence.values\n",
    "labels = data.label.values\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "# using the low level BERT for our task.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "input_ids = []\n",
    "for sent in sentences:\n",
    "    # so basically encode tokenizing , mapping sentences to thier token ids after adding special tokens.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence which are encoding.\n",
    "                        add_special_tokens = True, # Adding special tokens '[CLS]' and '[SEP]'\n",
    "\n",
    "                         )\n",
    "    \n",
    " \n",
    "    input_ids.append(encoded_sent)\n",
    "    \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN , truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Generating attention mask for sentences.\n",
    "    #   - when there is 0 present as token id we are going to set mask as 0.\n",
    "    #   - we are going to set mask 1 for all non-zero positive input id.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "   \n",
    "    attention_masks.append(att_mask)\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=0)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,test_size=0.2, random_state=0)\n",
    "\n",
    "#changing the numpy arrays into tensors for working on GPU. \n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Deciding the batch size for training.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = SequentialSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "N_test_DATAPOINTS = 8192 - len(train_inputs)\n",
    "\n",
    "# DataLoader for our validation(test) set.\n",
    "validation_data = TensorDataset(validation_inputs[0:N_test_DATAPOINTS], validation_masks[0:N_test_DATAPOINTS], validation_labels[0:N_test_DATAPOINTS])\n",
    "validation_labels = validation_labels[0:N_test_DATAPOINTS]\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7808f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = TensorDataset(torch.cat([train_inputs,validation_inputs[0:N_test_DATAPOINTS]]),\n",
    "                             torch.cat([train_masks,validation_masks[0:N_test_DATAPOINTS]]),\n",
    "                             torch.cat([train_labels,validation_labels[0:N_test_DATAPOINTS]])\n",
    "                            )\n",
    "\n",
    "combined_sampler = SequentialSampler(combined_data)\n",
    "combined_loader = DataLoader(combined_data, sampler=combined_sampler, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb953db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626a0b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cad729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in combined_loader:\n",
    "    batch = [x.cuda() for x in batch]\n",
    "    input_shape = batch[0].shape\n",
    "    token_type_ids = torch.zeros(input_shape, dtype=torch.long, device='cuda')\n",
    "    batch = [batch[0], token_type_ids, batch[1], batch[2]]\n",
    "    batch = {'input_ids':batch[0],\n",
    "            'attention_mask':batch[2],\n",
    "            'token_type_ids':batch[1],}\n",
    "    output = model(**batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fa2fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.9025,  4.0273],\n",
       "        [ 3.2860, -3.0037],\n",
       "        [ 3.4921, -3.5253],\n",
       "        [-3.8537,  3.6846],\n",
       "        [-4.2034,  3.9416],\n",
       "        [-3.3182,  2.9934],\n",
       "        [-4.1019,  3.8999],\n",
       "        [ 3.7243, -3.7942]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f0a63",
   "metadata": {},
   "source": [
    "# Start TRAK for trNTK computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c466d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trak\n",
    "TRAKer = trak.TRAKer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7d4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:TRAK:TRAK is still in an early 0.x.x version.\n",
      "                             Report any issues at https://github.com/MadryLab/trak/issues\n",
      "INFO:STORE:Existing model IDs in /rcfs/projects/task0_pmml/proj_trNTK/BERT/BERT_pNTK_full: [0, 1, 2]\n",
      "INFO:STORE:No model IDs in /rcfs/projects/task0_pmml/proj_trNTK/BERT/BERT_pNTK_full have been finalized.\n",
      "INFO:STORE:No existing TRAK scores in /rcfs/projects/task0_pmml/proj_trNTK/BERT/BERT_pNTK_full.\n"
     ]
    }
   ],
   "source": [
    "traker = TRAKer(model=model,\n",
    "                task='text_pNTK',\n",
    "                save_dir = '/rcfs/projects/task0_pmml/proj_trNTK/BERT/BERT_pNTK_full/',\n",
    "                train_set_size=len(train_inputs)+len(validation_inputs[0:N_test_DATAPOINTS]),\n",
    "                num_classes=None, #probably fails for number of classes = 1; should be number of neurons!\n",
    "                proj_dim=0, #note, needed to use less memory. \n",
    "                use_half_precision=False,\n",
    "                proj_max_batch_size=8,\n",
    "                projector=trak.projectors.NoOpProjector())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e2127",
   "metadata": {},
   "source": [
    "# Seem to have to use BasicProjector because the kernel is not built to handle the integer valued inputs to text models> should raise a bug on TRAK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7335ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traker.projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863715fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7794a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#func_weights = dict(model.named_parameters())\n",
    "#func_buffers = dict(model.named_buffers())\n",
    "\n",
    "#torch.func.functional_call(model,(func_weights, func_buffers),args=None,kwargs=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9d6983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:00<00:00, 4268.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:00<00:00, 4282.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1024/1024 [33:18<00:00,  1.95s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1024/1024 [3:33:31<00:00, 12.51s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_id, ckpt in enumerate(ckpts):\n",
    "    # TRAKer loads the provided checkpoint and also associates\n",
    "    # the provided (unique) model_id with the checkpoint.\n",
    "    traker.load_checkpoint(ckpt, model_id=model_id)\n",
    "\n",
    "    for batch in tqdm(combined_loader):\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        input_shape = batch[0].shape\n",
    "        token_type_ids = torch.zeros(input_shape, dtype=torch.long, device='cuda')\n",
    "        batch = [batch[0], token_type_ids, batch[1], batch[2]]\n",
    "        # TRAKer computes features corresponding to the batch of examples,\n",
    "        # using the checkpoint loaded above.\n",
    "        traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "# Tells TRAKer that we've given it all the information, at which point\n",
    "# TRAKer does some post-processing to get ready for the next step\n",
    "# (scoring target examples).\n",
    "#traker.finalize_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45b27d",
   "metadata": {},
   "source": [
    "### full pNTK calculation = approx 3:21:39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6017306",
   "metadata": {},
   "source": [
    "# Embedding Bert-- only run if you didnt run Trak, Trak eats too much memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287e4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "all_inputs = torch.cat([train_inputs,validation_inputs[0:N_test_DATAPOINTS]]).cuda()\n",
    "all_masks = torch.cat([train_masks,validation_masks[0:N_test_DATAPOINTS]]).cuda()\n",
    "all_labels = torch.cat([train_labels,validation_labels[0:N_test_DATAPOINTS]]).cuda()\n",
    "\n",
    "all_data = TensorDataset(all_inputs, all_masks, all_labels)\n",
    "all_data_sampler = SequentialSampler(all_data)\n",
    "all_dataloader = DataLoader(all_data, sampler=all_data_sampler, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c3dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bert\n",
      "bert.embeddings\n",
      "bert.embeddings.word_embeddings\n",
      "bert.embeddings.position_embeddings\n",
      "bert.embeddings.token_type_embeddings\n",
      "bert.embeddings.LayerNorm\n",
      "bert.embeddings.dropout\n",
      "bert.encoder\n",
      "bert.encoder.layer\n",
      "bert.encoder.layer.0\n",
      "bert.encoder.layer.0.attention\n",
      "bert.encoder.layer.0.attention.self\n",
      "bert.encoder.layer.0.attention.self.query\n",
      "bert.encoder.layer.0.attention.self.key\n",
      "bert.encoder.layer.0.attention.self.value\n",
      "bert.encoder.layer.0.attention.self.dropout\n",
      "bert.encoder.layer.0.attention.output\n",
      "bert.encoder.layer.0.attention.output.dense\n",
      "bert.encoder.layer.0.attention.output.LayerNorm\n",
      "bert.encoder.layer.0.attention.output.dropout\n",
      "bert.encoder.layer.0.intermediate\n",
      "bert.encoder.layer.0.intermediate.dense\n",
      "bert.encoder.layer.0.intermediate.intermediate_act_fn\n",
      "bert.encoder.layer.0.output\n",
      "bert.encoder.layer.0.output.dense\n",
      "bert.encoder.layer.0.output.LayerNorm\n",
      "bert.encoder.layer.0.output.dropout\n",
      "bert.encoder.layer.1\n",
      "bert.encoder.layer.1.attention\n",
      "bert.encoder.layer.1.attention.self\n",
      "bert.encoder.layer.1.attention.self.query\n",
      "bert.encoder.layer.1.attention.self.key\n",
      "bert.encoder.layer.1.attention.self.value\n",
      "bert.encoder.layer.1.attention.self.dropout\n",
      "bert.encoder.layer.1.attention.output\n",
      "bert.encoder.layer.1.attention.output.dense\n",
      "bert.encoder.layer.1.attention.output.LayerNorm\n",
      "bert.encoder.layer.1.attention.output.dropout\n",
      "bert.encoder.layer.1.intermediate\n",
      "bert.encoder.layer.1.intermediate.dense\n",
      "bert.encoder.layer.1.output\n",
      "bert.encoder.layer.1.output.dense\n",
      "bert.encoder.layer.1.output.LayerNorm\n",
      "bert.encoder.layer.1.output.dropout\n",
      "bert.encoder.layer.2\n",
      "bert.encoder.layer.2.attention\n",
      "bert.encoder.layer.2.attention.self\n",
      "bert.encoder.layer.2.attention.self.query\n",
      "bert.encoder.layer.2.attention.self.key\n",
      "bert.encoder.layer.2.attention.self.value\n",
      "bert.encoder.layer.2.attention.self.dropout\n",
      "bert.encoder.layer.2.attention.output\n",
      "bert.encoder.layer.2.attention.output.dense\n",
      "bert.encoder.layer.2.attention.output.LayerNorm\n",
      "bert.encoder.layer.2.attention.output.dropout\n",
      "bert.encoder.layer.2.intermediate\n",
      "bert.encoder.layer.2.intermediate.dense\n",
      "bert.encoder.layer.2.output\n",
      "bert.encoder.layer.2.output.dense\n",
      "bert.encoder.layer.2.output.LayerNorm\n",
      "bert.encoder.layer.2.output.dropout\n",
      "bert.encoder.layer.3\n",
      "bert.encoder.layer.3.attention\n",
      "bert.encoder.layer.3.attention.self\n",
      "bert.encoder.layer.3.attention.self.query\n",
      "bert.encoder.layer.3.attention.self.key\n",
      "bert.encoder.layer.3.attention.self.value\n",
      "bert.encoder.layer.3.attention.self.dropout\n",
      "bert.encoder.layer.3.attention.output\n",
      "bert.encoder.layer.3.attention.output.dense\n",
      "bert.encoder.layer.3.attention.output.LayerNorm\n",
      "bert.encoder.layer.3.attention.output.dropout\n",
      "bert.encoder.layer.3.intermediate\n",
      "bert.encoder.layer.3.intermediate.dense\n",
      "bert.encoder.layer.3.output\n",
      "bert.encoder.layer.3.output.dense\n",
      "bert.encoder.layer.3.output.LayerNorm\n",
      "bert.encoder.layer.3.output.dropout\n",
      "bert.encoder.layer.4\n",
      "bert.encoder.layer.4.attention\n",
      "bert.encoder.layer.4.attention.self\n",
      "bert.encoder.layer.4.attention.self.query\n",
      "bert.encoder.layer.4.attention.self.key\n",
      "bert.encoder.layer.4.attention.self.value\n",
      "bert.encoder.layer.4.attention.self.dropout\n",
      "bert.encoder.layer.4.attention.output\n",
      "bert.encoder.layer.4.attention.output.dense\n",
      "bert.encoder.layer.4.attention.output.LayerNorm\n",
      "bert.encoder.layer.4.attention.output.dropout\n",
      "bert.encoder.layer.4.intermediate\n",
      "bert.encoder.layer.4.intermediate.dense\n",
      "bert.encoder.layer.4.output\n",
      "bert.encoder.layer.4.output.dense\n",
      "bert.encoder.layer.4.output.LayerNorm\n",
      "bert.encoder.layer.4.output.dropout\n",
      "bert.encoder.layer.5\n",
      "bert.encoder.layer.5.attention\n",
      "bert.encoder.layer.5.attention.self\n",
      "bert.encoder.layer.5.attention.self.query\n",
      "bert.encoder.layer.5.attention.self.key\n",
      "bert.encoder.layer.5.attention.self.value\n",
      "bert.encoder.layer.5.attention.self.dropout\n",
      "bert.encoder.layer.5.attention.output\n",
      "bert.encoder.layer.5.attention.output.dense\n",
      "bert.encoder.layer.5.attention.output.LayerNorm\n",
      "bert.encoder.layer.5.attention.output.dropout\n",
      "bert.encoder.layer.5.intermediate\n",
      "bert.encoder.layer.5.intermediate.dense\n",
      "bert.encoder.layer.5.output\n",
      "bert.encoder.layer.5.output.dense\n",
      "bert.encoder.layer.5.output.LayerNorm\n",
      "bert.encoder.layer.5.output.dropout\n",
      "bert.encoder.layer.6\n",
      "bert.encoder.layer.6.attention\n",
      "bert.encoder.layer.6.attention.self\n",
      "bert.encoder.layer.6.attention.self.query\n",
      "bert.encoder.layer.6.attention.self.key\n",
      "bert.encoder.layer.6.attention.self.value\n",
      "bert.encoder.layer.6.attention.self.dropout\n",
      "bert.encoder.layer.6.attention.output\n",
      "bert.encoder.layer.6.attention.output.dense\n",
      "bert.encoder.layer.6.attention.output.LayerNorm\n",
      "bert.encoder.layer.6.attention.output.dropout\n",
      "bert.encoder.layer.6.intermediate\n",
      "bert.encoder.layer.6.intermediate.dense\n",
      "bert.encoder.layer.6.output\n",
      "bert.encoder.layer.6.output.dense\n",
      "bert.encoder.layer.6.output.LayerNorm\n",
      "bert.encoder.layer.6.output.dropout\n",
      "bert.encoder.layer.7\n",
      "bert.encoder.layer.7.attention\n",
      "bert.encoder.layer.7.attention.self\n",
      "bert.encoder.layer.7.attention.self.query\n",
      "bert.encoder.layer.7.attention.self.key\n",
      "bert.encoder.layer.7.attention.self.value\n",
      "bert.encoder.layer.7.attention.self.dropout\n",
      "bert.encoder.layer.7.attention.output\n",
      "bert.encoder.layer.7.attention.output.dense\n",
      "bert.encoder.layer.7.attention.output.LayerNorm\n",
      "bert.encoder.layer.7.attention.output.dropout\n",
      "bert.encoder.layer.7.intermediate\n",
      "bert.encoder.layer.7.intermediate.dense\n",
      "bert.encoder.layer.7.output\n",
      "bert.encoder.layer.7.output.dense\n",
      "bert.encoder.layer.7.output.LayerNorm\n",
      "bert.encoder.layer.7.output.dropout\n",
      "bert.encoder.layer.8\n",
      "bert.encoder.layer.8.attention\n",
      "bert.encoder.layer.8.attention.self\n",
      "bert.encoder.layer.8.attention.self.query\n",
      "bert.encoder.layer.8.attention.self.key\n",
      "bert.encoder.layer.8.attention.self.value\n",
      "bert.encoder.layer.8.attention.self.dropout\n",
      "bert.encoder.layer.8.attention.output\n",
      "bert.encoder.layer.8.attention.output.dense\n",
      "bert.encoder.layer.8.attention.output.LayerNorm\n",
      "bert.encoder.layer.8.attention.output.dropout\n",
      "bert.encoder.layer.8.intermediate\n",
      "bert.encoder.layer.8.intermediate.dense\n",
      "bert.encoder.layer.8.output\n",
      "bert.encoder.layer.8.output.dense\n",
      "bert.encoder.layer.8.output.LayerNorm\n",
      "bert.encoder.layer.8.output.dropout\n",
      "bert.encoder.layer.9\n",
      "bert.encoder.layer.9.attention\n",
      "bert.encoder.layer.9.attention.self\n",
      "bert.encoder.layer.9.attention.self.query\n",
      "bert.encoder.layer.9.attention.self.key\n",
      "bert.encoder.layer.9.attention.self.value\n",
      "bert.encoder.layer.9.attention.self.dropout\n",
      "bert.encoder.layer.9.attention.output\n",
      "bert.encoder.layer.9.attention.output.dense\n",
      "bert.encoder.layer.9.attention.output.LayerNorm\n",
      "bert.encoder.layer.9.attention.output.dropout\n",
      "bert.encoder.layer.9.intermediate\n",
      "bert.encoder.layer.9.intermediate.dense\n",
      "bert.encoder.layer.9.output\n",
      "bert.encoder.layer.9.output.dense\n",
      "bert.encoder.layer.9.output.LayerNorm\n",
      "bert.encoder.layer.9.output.dropout\n",
      "bert.encoder.layer.10\n",
      "bert.encoder.layer.10.attention\n",
      "bert.encoder.layer.10.attention.self\n",
      "bert.encoder.layer.10.attention.self.query\n",
      "bert.encoder.layer.10.attention.self.key\n",
      "bert.encoder.layer.10.attention.self.value\n",
      "bert.encoder.layer.10.attention.self.dropout\n",
      "bert.encoder.layer.10.attention.output\n",
      "bert.encoder.layer.10.attention.output.dense\n",
      "bert.encoder.layer.10.attention.output.LayerNorm\n",
      "bert.encoder.layer.10.attention.output.dropout\n",
      "bert.encoder.layer.10.intermediate\n",
      "bert.encoder.layer.10.intermediate.dense\n",
      "bert.encoder.layer.10.output\n",
      "bert.encoder.layer.10.output.dense\n",
      "bert.encoder.layer.10.output.LayerNorm\n",
      "bert.encoder.layer.10.output.dropout\n",
      "bert.encoder.layer.11\n",
      "bert.encoder.layer.11.attention\n",
      "bert.encoder.layer.11.attention.self\n",
      "bert.encoder.layer.11.attention.self.query\n",
      "bert.encoder.layer.11.attention.self.key\n",
      "bert.encoder.layer.11.attention.self.value\n",
      "bert.encoder.layer.11.attention.self.dropout\n",
      "bert.encoder.layer.11.attention.output\n",
      "bert.encoder.layer.11.attention.output.dense\n",
      "bert.encoder.layer.11.attention.output.LayerNorm\n",
      "bert.encoder.layer.11.attention.output.dropout\n",
      "bert.encoder.layer.11.intermediate\n",
      "bert.encoder.layer.11.intermediate.dense\n",
      "bert.encoder.layer.11.output\n",
      "bert.encoder.layer.11.output.dense\n",
      "bert.encoder.layer.11.output.LayerNorm\n",
      "bert.encoder.layer.11.output.dropout\n",
      "bert.pooler\n",
      "bert.pooler.dense\n",
      "bert.pooler.activation\n",
      "dropout\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "ALL_NAMES = []\n",
    "for name,module in model.named_modules():\n",
    "    print(name)\n",
    "    if 'activation' in name:\n",
    "        continue\n",
    "    if 'dropout' in name:\n",
    "        continue\n",
    "    if 'bert'==name:\n",
    "        continue\n",
    "    if 'bert.encoder'==name:\n",
    "        continue\n",
    "    if 'bert.encoder.layer'==name:\n",
    "        continue\n",
    "    if 'relu' in name:\n",
    "        continue\n",
    "    if '' == name:\n",
    "        continue\n",
    "    #if len(name.split('.')) < 5 and 'bert.encoder.layer' in name:\n",
    "    #    continue\n",
    "        \n",
    "    ALL_NAMES.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db007d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings\n",
      "bert.embeddings.word_embeddings\n",
      "bert.embeddings.position_embeddings\n",
      "bert.embeddings.token_type_embeddings\n",
      "bert.embeddings.LayerNorm\n",
      "bert.encoder.layer.0\n",
      "bert.encoder.layer.0.attention\n",
      "bert.encoder.layer.0.attention.self\n",
      "bert.encoder.layer.0.attention.self.query\n",
      "bert.encoder.layer.0.attention.self.key\n",
      "bert.encoder.layer.0.attention.self.value\n",
      "bert.encoder.layer.0.attention.output\n",
      "bert.encoder.layer.0.attention.output.dense\n",
      "bert.encoder.layer.0.attention.output.LayerNorm\n",
      "bert.encoder.layer.0.intermediate\n",
      "bert.encoder.layer.0.intermediate.dense\n",
      "bert.encoder.layer.0.intermediate.intermediate_act_fn\n",
      "bert.encoder.layer.0.output\n",
      "bert.encoder.layer.0.output.dense\n",
      "bert.encoder.layer.0.output.LayerNorm\n",
      "bert.encoder.layer.1\n",
      "bert.encoder.layer.1.attention\n",
      "bert.encoder.layer.1.attention.self\n",
      "bert.encoder.layer.1.attention.self.query\n",
      "bert.encoder.layer.1.attention.self.key\n",
      "bert.encoder.layer.1.attention.self.value\n",
      "bert.encoder.layer.1.attention.output\n",
      "bert.encoder.layer.1.attention.output.dense\n",
      "bert.encoder.layer.1.attention.output.LayerNorm\n",
      "bert.encoder.layer.1.intermediate\n",
      "bert.encoder.layer.1.intermediate.dense\n",
      "bert.encoder.layer.1.output\n",
      "bert.encoder.layer.1.output.dense\n",
      "bert.encoder.layer.1.output.LayerNorm\n",
      "bert.encoder.layer.2\n",
      "bert.encoder.layer.2.attention\n",
      "bert.encoder.layer.2.attention.self\n",
      "bert.encoder.layer.2.attention.self.query\n",
      "bert.encoder.layer.2.attention.self.key\n",
      "bert.encoder.layer.2.attention.self.value\n",
      "bert.encoder.layer.2.attention.output\n",
      "bert.encoder.layer.2.attention.output.dense\n",
      "bert.encoder.layer.2.attention.output.LayerNorm\n",
      "bert.encoder.layer.2.intermediate\n",
      "bert.encoder.layer.2.intermediate.dense\n",
      "bert.encoder.layer.2.output\n",
      "bert.encoder.layer.2.output.dense\n",
      "bert.encoder.layer.2.output.LayerNorm\n",
      "bert.encoder.layer.3\n",
      "bert.encoder.layer.3.attention\n",
      "bert.encoder.layer.3.attention.self\n",
      "bert.encoder.layer.3.attention.self.query\n",
      "bert.encoder.layer.3.attention.self.key\n",
      "bert.encoder.layer.3.attention.self.value\n",
      "bert.encoder.layer.3.attention.output\n",
      "bert.encoder.layer.3.attention.output.dense\n",
      "bert.encoder.layer.3.attention.output.LayerNorm\n",
      "bert.encoder.layer.3.intermediate\n",
      "bert.encoder.layer.3.intermediate.dense\n",
      "bert.encoder.layer.3.output\n",
      "bert.encoder.layer.3.output.dense\n",
      "bert.encoder.layer.3.output.LayerNorm\n",
      "bert.encoder.layer.4\n",
      "bert.encoder.layer.4.attention\n",
      "bert.encoder.layer.4.attention.self\n",
      "bert.encoder.layer.4.attention.self.query\n",
      "bert.encoder.layer.4.attention.self.key\n",
      "bert.encoder.layer.4.attention.self.value\n",
      "bert.encoder.layer.4.attention.output\n",
      "bert.encoder.layer.4.attention.output.dense\n",
      "bert.encoder.layer.4.attention.output.LayerNorm\n",
      "bert.encoder.layer.4.intermediate\n",
      "bert.encoder.layer.4.intermediate.dense\n",
      "bert.encoder.layer.4.output\n",
      "bert.encoder.layer.4.output.dense\n",
      "bert.encoder.layer.4.output.LayerNorm\n",
      "bert.encoder.layer.5\n",
      "bert.encoder.layer.5.attention\n",
      "bert.encoder.layer.5.attention.self\n",
      "bert.encoder.layer.5.attention.self.query\n",
      "bert.encoder.layer.5.attention.self.key\n",
      "bert.encoder.layer.5.attention.self.value\n",
      "bert.encoder.layer.5.attention.output\n",
      "bert.encoder.layer.5.attention.output.dense\n",
      "bert.encoder.layer.5.attention.output.LayerNorm\n",
      "bert.encoder.layer.5.intermediate\n",
      "bert.encoder.layer.5.intermediate.dense\n",
      "bert.encoder.layer.5.output\n",
      "bert.encoder.layer.5.output.dense\n",
      "bert.encoder.layer.5.output.LayerNorm\n",
      "bert.encoder.layer.6\n",
      "bert.encoder.layer.6.attention\n",
      "bert.encoder.layer.6.attention.self\n",
      "bert.encoder.layer.6.attention.self.query\n",
      "bert.encoder.layer.6.attention.self.key\n",
      "bert.encoder.layer.6.attention.self.value\n",
      "bert.encoder.layer.6.attention.output\n",
      "bert.encoder.layer.6.attention.output.dense\n",
      "bert.encoder.layer.6.attention.output.LayerNorm\n",
      "bert.encoder.layer.6.intermediate\n",
      "bert.encoder.layer.6.intermediate.dense\n",
      "bert.encoder.layer.6.output\n",
      "bert.encoder.layer.6.output.dense\n",
      "bert.encoder.layer.6.output.LayerNorm\n",
      "bert.encoder.layer.7\n",
      "bert.encoder.layer.7.attention\n",
      "bert.encoder.layer.7.attention.self\n",
      "bert.encoder.layer.7.attention.self.query\n",
      "bert.encoder.layer.7.attention.self.key\n",
      "bert.encoder.layer.7.attention.self.value\n",
      "bert.encoder.layer.7.attention.output\n",
      "bert.encoder.layer.7.attention.output.dense\n",
      "bert.encoder.layer.7.attention.output.LayerNorm\n",
      "bert.encoder.layer.7.intermediate\n",
      "bert.encoder.layer.7.intermediate.dense\n",
      "bert.encoder.layer.7.output\n",
      "bert.encoder.layer.7.output.dense\n",
      "bert.encoder.layer.7.output.LayerNorm\n",
      "bert.encoder.layer.8\n",
      "bert.encoder.layer.8.attention\n",
      "bert.encoder.layer.8.attention.self\n",
      "bert.encoder.layer.8.attention.self.query\n",
      "bert.encoder.layer.8.attention.self.key\n",
      "bert.encoder.layer.8.attention.self.value\n",
      "bert.encoder.layer.8.attention.output\n",
      "bert.encoder.layer.8.attention.output.dense\n",
      "bert.encoder.layer.8.attention.output.LayerNorm\n",
      "bert.encoder.layer.8.intermediate\n",
      "bert.encoder.layer.8.intermediate.dense\n",
      "bert.encoder.layer.8.output\n",
      "bert.encoder.layer.8.output.dense\n",
      "bert.encoder.layer.8.output.LayerNorm\n",
      "bert.encoder.layer.9\n",
      "bert.encoder.layer.9.attention\n",
      "bert.encoder.layer.9.attention.self\n",
      "bert.encoder.layer.9.attention.self.query\n",
      "bert.encoder.layer.9.attention.self.key\n",
      "bert.encoder.layer.9.attention.self.value\n",
      "bert.encoder.layer.9.attention.output\n",
      "bert.encoder.layer.9.attention.output.dense\n",
      "bert.encoder.layer.9.attention.output.LayerNorm\n",
      "bert.encoder.layer.9.intermediate\n",
      "bert.encoder.layer.9.intermediate.dense\n",
      "bert.encoder.layer.9.output\n",
      "bert.encoder.layer.9.output.dense\n",
      "bert.encoder.layer.9.output.LayerNorm\n",
      "bert.encoder.layer.10\n",
      "bert.encoder.layer.10.attention\n",
      "bert.encoder.layer.10.attention.self\n",
      "bert.encoder.layer.10.attention.self.query\n",
      "bert.encoder.layer.10.attention.self.key\n",
      "bert.encoder.layer.10.attention.self.value\n",
      "bert.encoder.layer.10.attention.output\n",
      "bert.encoder.layer.10.attention.output.dense\n",
      "bert.encoder.layer.10.attention.output.LayerNorm\n",
      "bert.encoder.layer.10.intermediate\n",
      "bert.encoder.layer.10.intermediate.dense\n",
      "bert.encoder.layer.10.output\n",
      "bert.encoder.layer.10.output.dense\n",
      "bert.encoder.layer.10.output.LayerNorm\n",
      "bert.encoder.layer.11\n",
      "bert.encoder.layer.11.attention\n",
      "bert.encoder.layer.11.attention.self\n",
      "bert.encoder.layer.11.attention.self.query\n",
      "bert.encoder.layer.11.attention.self.key\n",
      "bert.encoder.layer.11.attention.self.value\n",
      "bert.encoder.layer.11.attention.output\n",
      "bert.encoder.layer.11.attention.output.dense\n",
      "bert.encoder.layer.11.attention.output.LayerNorm\n",
      "bert.encoder.layer.11.intermediate\n",
      "bert.encoder.layer.11.intermediate.dense\n",
      "bert.encoder.layer.11.output\n",
      "bert.encoder.layer.11.output.dense\n",
      "bert.encoder.layer.11.output.LayerNorm\n",
      "bert.pooler\n",
      "bert.pooler.dense\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "for name in ALL_NAMES:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "284157e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hooks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bdc417fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(model.hooks.keys()):\n",
    "    model.hooks[key].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f282c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        if type(output) is tuple:\n",
    "            if len(output)==1:\n",
    "                output = output[0]\n",
    "            else:\n",
    "                print(output[0].shape)\n",
    "                print(output[1].shape)\n",
    "                output = output[0]\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64405163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  5926,  2033,  ...,     0,     0,     0],\n",
       "        [  101,  1996,  2026,  ...,     0,     0,     0],\n",
       "        [  101,  2057, 10116,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2065,  2198,  ...,     0,     0,     0],\n",
       "        [  101,  1996,  2837,  ...,     0,     0,     0],\n",
       "        [  101,  5863,  3369,  ...,     0,     0,     0]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90bbd178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [02:38,  8.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(all_inputs[j\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m], \n\u001b[1;32m     27\u001b[0m                         token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     28\u001b[0m                         attention_mask\u001b[38;5;241m=\u001b[39mall_masks[j\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m], \n\u001b[1;32m     29\u001b[0m                         labels\u001b[38;5;241m=\u001b[39mall_labels[j\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m],\n\u001b[1;32m     30\u001b[0m                         output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m         X2_activation \u001b[38;5;241m=\u001b[39m activation[NAME]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m         component \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_activation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX2_activation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m         EM_Component[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m,j\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m] \u001b[38;5;241m=\u001b[39m component\n\u001b[1;32m     37\u001b[0m outer_Em_Kernel\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m EM_Component\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for modelnum in range(4):\n",
    "    outer_Em_Kernel = 0\n",
    "    print('starting: ',modelnum)\n",
    "    model.load_state_dict(ckpts[modelnum])\n",
    "    model.eval()\n",
    "    for k,NAME in tqdm(enumerate(ALL_NAMES)):\n",
    "        if os.path.exists(f'/rcfs/projects/task0_pmml/BERT/Em_kernel_components/{modelnum}/{NAME}-{k}.pt'):\n",
    "            continue\n",
    "        EM_Component = torch.zeros((len(all_masks),len(all_masks)),device='cpu')\n",
    "        \n",
    "        for name, module in model.named_modules():\n",
    "            if name == NAME:\n",
    "                model.hooks[NAME] = module.register_forward_hook(get_activation(NAME))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(8):\n",
    "                activation = {}\n",
    "                outputs = model(all_inputs[i*1024:(i+1)*1024], \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=all_masks[i*1024:(i+1)*1024], \n",
    "                                labels=all_labels[i*1024:(i+1)*1024],\n",
    "                                output_hidden_states=False)\n",
    "                X1_activation = activation[NAME].reshape(1024,-1)\n",
    "                for j in range(8):\n",
    "                    activation = {}\n",
    "                    outputs = model(all_inputs[j*1024:(j+1)*1024], \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=all_masks[j*1024:(j+1)*1024], \n",
    "                                    labels=all_labels[j*1024:(j+1)*1024],\n",
    "                                    output_hidden_states=False)\n",
    "                    X2_activation = activation[NAME].reshape(1024,-1)\n",
    "\n",
    "\n",
    "\n",
    "                    component = torch.matmul(X1_activation,X2_activation.T).cpu()\n",
    "                    EM_Component[i*1024:(i+1)*1024,j*1024:(j+1)*1024] = component\n",
    "            outer_Em_Kernel+= EM_Component\n",
    "            torch.save(EM_Component,f'/rcfs/projects/task0_pmml/BERT/Em_kernel_components/{modelnum}/{NAME}-{k}.pt')\n",
    "            model.hooks[NAME].remove()\n",
    "    #torch.save(outer_Em_Kernel,f'/rcfs/projects/task0_pmml/BERT/Em_kernels/seed{modelnum}.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
