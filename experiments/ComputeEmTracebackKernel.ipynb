{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac02952",
   "metadata": {},
   "source": [
    "This notebooks computed the embedding kernel for a pre-trained CNN on CIFAR10 badnet data. the dataset can be downloaded from https://github.com/Shawn-Shan/forensics, and the model training is described in XXX. \n",
    "\n",
    "The NTK computation is then described in XYZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc6f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import rearrange\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0955a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/rcfs/projects/task0_pmml/traceback/forensics/results/cifar_cifar2_res.p','rb') as f:\n",
    "    RES = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5814b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv2d = torch.nn.Conv2d(3, 32, (3,3), padding=(1,1),)\n",
    "        self.batch_normalization = torch.nn.BatchNorm2d(32,momentum=0.01,eps=1e-3)\n",
    "        self.conv2d_1 = torch.nn.Conv2d(32, 32, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_1 = torch.nn.BatchNorm2d(32,momentum=0.01,eps=1e-3)\n",
    "        self.max_pooling2d = torch.nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_2 = torch.nn.BatchNorm2d(64,momentum=0.01,eps=1e-3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_3 = torch.nn.BatchNorm2d(64,momentum=0.01,eps=1e-3)\n",
    "        self.max_pooling2d_1 = torch.nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 128, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_4 = torch.nn.BatchNorm2d(128,momentum=0.01,eps=1e-3)\n",
    "        self.conv2d_5 = torch.nn.Conv2d(128, 128, (3,3), padding=(1,1))\n",
    "        self.batch_normalization_5 = torch.nn.BatchNorm2d(128,momentum=0.01,eps=1e-3)\n",
    "        self.max_pooling2d_2 = torch.nn.MaxPool2d((2,2))\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.max_pooling1d = torch.nn.MaxPool1d((4))\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.dense = torch.nn.Linear(512,512,)\n",
    "        self.batch_normalization_6 = torch.nn.BatchNorm1d(512,momentum=0.01,eps=1e-3)\n",
    "        \n",
    "        self.dense_1 = torch.nn.Linear(512,512,)\n",
    "        self.batch_normalization_7 = torch.nn.BatchNorm1d(512,momentum=0.01,eps=1e-3)\n",
    "        \n",
    "        self.dense_2 = torch.nn.Linear(512,10,)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv2d(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization(x)\n",
    "        x = self.conv2d_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_1(x)\n",
    "        x = self.max_pooling2d(x)\n",
    "        \n",
    "        x = self.conv2d_2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_3(x)\n",
    "        x = self.max_pooling2d_1(x)\n",
    "        \n",
    "        x = self.conv2d_4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_4(x)\n",
    "        x = self.conv2d_5(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_5(x)\n",
    "        x = self.max_pooling2d_2(x)\n",
    "        \n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.max_pooling1d(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.dense(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_6(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.batch_normalization_7(x)\n",
    "        x = self.dense_2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29524d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to('cuda')\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(),1e-2,momentum=0.9,nesterov=True)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dccfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES.keys()\n",
    "\n",
    "train_x = rearrange(torch.tensor(RES['injected_X'],dtype=torch.float32),'b h w c -> b c h w')\n",
    "train_y = torch.tensor(RES['injected_Y'],dtype=torch.float32)\n",
    "\n",
    "test_x = rearrange(torch.tensor(RES['injected_X_test'],dtype=torch.float32),'b h w c -> b c h w')\n",
    "test_y = torch.tensor(RES['injected_Y_test'],dtype=torch.float32)\n",
    "\n",
    "test_x_og = rearrange(torch.tensor(RES['X_test'],dtype=torch.float32),'b h w c -> b c h w')\n",
    "test_y_og = torch.tensor(RES['Y_test'],dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x,train_y),batch_size=128,shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_x,test_y),batch_size=1,shuffle=False)\n",
    "test_loader_og = DataLoader(TensorDataset(test_x_og,test_y_og),batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30bc8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = torch.cat([train_x,test_x,test_x_og]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e543ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/rcfs/projects/task0_pmml/MODELS/poisoned_CNN.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07b0173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e80f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hooks = {}\n",
    "for key in list(model.hooks.keys()):\n",
    "    model.hooks[key].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4862072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv2d\n",
      "batch_normalization\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "max_pooling2d\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "max_pooling2d_1\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "conv2d_5\n",
      "batch_normalization_5\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "max_pooling1d\n",
      "dropout\n",
      "dense\n",
      "batch_normalization_6\n",
      "dense_1\n",
      "batch_normalization_7\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "ALL_NAMES = []\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "    if '' == name:\n",
    "        continue\n",
    "    if 'dropout' in name:\n",
    "        continue\n",
    "    if 'flatten' in name:\n",
    "        continue\n",
    "        \n",
    "    ALL_NAMES.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee44505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "batch_normalization\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "max_pooling2d\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "max_pooling2d_1\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "conv2d_5\n",
      "batch_normalization_5\n",
      "max_pooling2d_2\n",
      "max_pooling1d\n",
      "dense\n",
      "batch_normalization_6\n",
      "dense_1\n",
      "batch_normalization_7\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "for name in ALL_NAMES:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9ffbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e595b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:28<00:00,  4.11s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.85s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:29<00:00,  4.18s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:27<00:00,  3.87s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:16<00:00,  2.37s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:16<00:00,  2.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:16<00:00,  2.37s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:16<00:00,  2.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.27s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.14s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.16s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.15s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.16s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.15s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:07<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "total_em = 0\n",
    "model.eval()\n",
    "for k,NAME in enumerate(ALL_NAMES):\n",
    "    EM_Component = torch.zeros((70_000,70_000),device='cpu')\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if name == NAME:\n",
    "            model.hooks[name] = module.register_forward_hook(get_activation(name))\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(7)):\n",
    "            activation = {}\n",
    "            X1 =  model.forward(all_X[i*10_000:(i+1)*10_000,])\n",
    "            X1_activation = activation[NAME].reshape(10_000,-1)\n",
    "            for j in range(7):\n",
    "                activation = {}\n",
    "                X2 =  model.forward(all_X[j*10_000:(j+1)*10_000,])\n",
    "                X2_activation = activation[NAME].reshape(10_000,-1)\n",
    "                \n",
    "                component = torch.matmul(X1_activation,X2_activation.T).cpu()\n",
    "                EM_Component[i*10_000:(i+1)*10_000,j*10_000:(j+1)*10_000] = component\n",
    "    \n",
    "    torch.save(EM_Component,f'/rcfs/projects/task0_pmml/traceback/kernels/Em_comp/{NAME}-{k}.pt')\n",
    "    total_em+=EM_Component\n",
    "    model.hooks[NAME].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05432160",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/rcfs/projects/task0_pmml/traceback/kernels/embedding.npy',total_em.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
