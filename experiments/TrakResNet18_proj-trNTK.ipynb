{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd21228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708961cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PATH = sys.path\n",
    "newPATH = ['/rcfs/projects/task0_pmml/TRAKfork/trak',] + PATH\n",
    "sys.path = newPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c0d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using 1 model because we have only 1 model?\n",
    "ckpts = [torch.load('/rcfs/projects/task0_pmml/MODELS/resnet18.pt'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91ae9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trak import TRAKer\n",
    "from trak.modelout_functions import trNTKModelOutput "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93a554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver = savers.Mmapsaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08962ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "__all__ = [\n",
    "    \"ResNet\",\n",
    "    \"resnet18\",\n",
    "    \"resnet34\",\n",
    "    \"resnet50\",\n",
    "]\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        groups=1,\n",
    "        base_width=64,\n",
    "        dilation=1,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        groups=1,\n",
    "        base_width=64,\n",
    "        dilation=1,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block,\n",
    "        layers,\n",
    "        num_classes=10,\n",
    "        zero_init_residual=False,\n",
    "        groups=1,\n",
    "        width_per_group=64,\n",
    "        replace_stride_with_dilation=None,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        # CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        # END\n",
    "\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                stride,\n",
    "                downsample,\n",
    "                self.groups,\n",
    "                self.base_width,\n",
    "                previous_dilation,\n",
    "                norm_layer,\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        z = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(z)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def forward_cam_conv1(self, x):\n",
    "        y = self.conv1(x)\n",
    "        x = self.bn1(y)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        z = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(z)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def forward_conv1(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    def forward_bn1(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        return x\n",
    "    def forward_layer1(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "    def forward_layer2(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "    def forward_layer3(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    def forward_layer4(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    def forward_flat(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, device, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        script_dir = os.path.dirname(__file__)\n",
    "        state_dict = torch.load(\n",
    "            script_dir + \"/state_dicts/\" + arch + \".pt\", map_location=device\n",
    "        )\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, progress=True, device=\"cpu\", **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\n",
    "        \"resnet18\", BasicBlock, [2, 2, 2, 2], pretrained, progress, device, **kwargs\n",
    "    )\n",
    "\n",
    "def resnet34(pretrained=False, progress=True, device=\"cpu\", **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\n",
    "        \"resnet34\", BasicBlock, [3, 4, 6, 3], pretrained, progress, device, **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, device=\"cpu\", **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\n",
    "        \"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, device, **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f4759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'ResNet18'\n",
    "model = resnet18(device='cuda').to(memory_format=torch.channels_last).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e19e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e57d274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:TRAK:TRAK is still in an early 0.x.x version.\n",
      "                             Report any issues at https://github.com/MadryLab/trak/issues\n",
      "INFO:STORE:Existing model IDs in /rcfs/projects/task0_pmml/proj_trNTK/test_blind: [0]\n",
      "INFO:STORE:No model IDs in /rcfs/projects/task0_pmml/proj_trNTK/test_blind have been finalized.\n",
      "INFO:STORE:No existing TRAK scores in /rcfs/projects/task0_pmml/proj_trNTK/test_blind.\n"
     ]
    }
   ],
   "source": [
    "traker = TRAKer(model=model,\n",
    "                task='trNTK',\n",
    "                save_dir = '/rcfs/projects/task0_pmml/proj_trNTK/test_blind/',\n",
    "                train_set_size=60_000,\n",
    "                num_classes=10,\n",
    "                proj_dim=512*20,\n",
    "                proj_max_batch_size=16,\n",
    "                use_half_precision=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4422805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3321b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils2 import process_Cifar10\n",
    "train, test, combined = process_Cifar10('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a3ef6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(\n",
    "    root = '/people/enge625/NOTEBOOKS/',\n",
    "    train = True,                          \n",
    "    download = False,            \n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root = '/people/enge625/NOTEBOOKS/', \n",
    "    train = False, \n",
    "    download=False,\n",
    ")\n",
    "\n",
    "\n",
    "train_x = torch.tensor(train_data.data)\n",
    "test_x = torch.tensor(test_data.data)\n",
    "\n",
    "train_y = torch.tensor(train_data.targets)\n",
    "test_y = torch.tensor(test_data.targets)\n",
    "\n",
    "train_x_plot = torch.tensor(train_data.data).cpu().numpy()\n",
    "test_x_plot = torch.tensor(test_data.data).cpu().numpy()\n",
    "\n",
    "train_y_plot = torch.tensor(train_data.targets).cpu().numpy()\n",
    "test_y_plot = torch.tensor(test_data.targets).cpu().numpy()\n",
    "\n",
    "train_x = train_x/255\n",
    "test_x = test_x/255\n",
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "std = torch.tensor([0.2471, 0.2435, 0.2616])\n",
    "\n",
    "test_x -= mean[None,None,None,:]\n",
    "test_x /= std[None,None,None,:]\n",
    "\n",
    "train_x -= mean[None,None,None,:]\n",
    "train_x /= std[None,None,None,:]\n",
    "\n",
    "train_y = train_y.float()\n",
    "test_y = test_y.float()\n",
    "\n",
    "train_x = train_x.to('cuda')\n",
    "train_y = train_y.to('cuda')\n",
    "\n",
    "test_x = test_x.to('cuda')\n",
    "test_y = test_y.to('cuda')\n",
    "\n",
    "train_x = rearrange(train_x,'b w h f -> b f w h')\n",
    "test_x = rearrange(test_x,'b w h f -> b f w h')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_loader = DataLoader(train,batch_size=64,shuffle=False)\n",
    "test_loader = DataLoader(test,batch_size=64,shuffle=False)\n",
    "test_loader2 = DataLoader(test,batch_size=150,shuffle=False)\n",
    "combined_loader = DataLoader(combined,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "390da9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_loader.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43345a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "736aea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/938 [00:00<?, ?it/s]/tmp/ipykernel_8965/1305669240.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[1] = torch.tensor(batch[1],dtype=torch.long)\n",
      "  6%|████▊                                                                           | 56/938 [04:30<1:10:55,  4.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m         batch[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch[\u001b[38;5;241m1\u001b[39m],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# TRAKer computes features corresponding to the batch of examples,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# using the checkpoint loaded above.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mtraker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Tells TRAKer that we've given it all the information, at which point\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# TRAKer does some post-processing to get ready for the next step\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# (scoring target examples).\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#traker.finalize_features()\u001b[39;00m\n",
      "File \u001b[0;32m/rcfs/projects/task0_pmml/TRAKfork/trak/trak/traker.py:281\u001b[0m, in \u001b[0;36mTRAKer.featurize\u001b[0;34m(self, batch, inds, num_samples)\u001b[0m\n\u001b[1;32m    279\u001b[0m         grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojector\u001b[38;5;241m.\u001b[39mproject(grads, model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaver\u001b[38;5;241m.\u001b[39mcurrent_model_id)\n\u001b[1;32m    280\u001b[0m         grads \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_factor\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaver\u001b[38;5;241m.\u001b[39mcurrent_store[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrads_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][inds] \u001b[38;5;241m=\u001b[39m \u001b[43mgrads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_computer\u001b[38;5;241m.\u001b[39mcompute_per_sample_grad(batch\u001b[38;5;241m=\u001b[39mbatch)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for model_id, ckpt in enumerate(ckpts):\n",
    "    # TRAKer loads the provided checkpoint and also associates\n",
    "    # the provided (unique) model_id with the checkpoint.\n",
    "    traker.load_checkpoint(ckpt, model_id=model_id)\n",
    "\n",
    "    for batch in tqdm(combined_loader):\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        batch[1] = torch.tensor(batch[1],dtype=torch.long)\n",
    "        # TRAKer computes features corresponding to the batch of examples,\n",
    "        # using the checkpoint loaded above.\n",
    "        traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "# Tells TRAKer that we've given it all the information, at which point\n",
    "# TRAKer does some post-processing to get ready for the next step\n",
    "# (scoring target examples).\n",
    "#traker.finalize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e21866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for c in range(traker.num_classes):\n",
    "    np.save(f'/rcfs/projects/task0_pmml/proj_trNTK/resnet18_trNTK/largegrads_{c}.npy',traker.saver.current_store[f'grads_{c}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42705fc",
   "metadata": {},
   "source": [
    "# run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fe0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81602e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_savepath = traker.save_dir.joinpath('0/grads.mmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.from_numpy(np.load(grad_savepath)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_NTK = torch.matmul(A,A.T).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_NTK_savepath = traker.save_dir.joinpath('0/proj_pntk.npy')\n",
    "np.save(proj_NTK_savepath,proj_NTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41677f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_NTK.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f10a5c",
   "metadata": {},
   "source": [
    "# This should save to store:\n",
    "\n",
    "\n",
    "# Below, kept for posterity, my old wrong way of computing the attributions. Instead, we load the features from the saver_store of Trak, compute the NTK by matrix multiplying the features, and end up with an object that is like all the other NTK objects I analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id, checkpoint in enumerate(ckpts):\n",
    "    traker.start_scoring_checkpoint(checkpoint, model_id=model_id, num_targets=len(test))\n",
    "    for batch in test_loader:\n",
    "        batch[1] = torch.tensor(batch[1],dtype=torch.long)\n",
    "        traker.score(batch=batch,num_samples=batch[0].shape[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4372d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = traker.finalize_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id, checkpoint in enumerate(ckpts):\n",
    "    traker.start_scoring_checkpoint(checkpoint, model_id=model_id, num_targets=len(train))\n",
    "    for batch in train_loader:\n",
    "        batch[1] = torch.tensor(batch[1],dtype=torch.long)\n",
    "        traker.score(batch=batch,num_samples=batch[0].shape[0])\n",
    "        \n",
    "scores_train = traker.finalize_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f946c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44272b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.sum(scores_test,axis=0)\n",
    "#this should be outputting line 19, log(p/(1-p)) ; which is the logit of the correct class\n",
    "\n",
    "#which IS what I'm doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f214fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(g,'./trak_results/scores/CIFAR10_test_logits_of_correct_class.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
